<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Streamer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            text-align: center;
            padding: 50px;
        }
        #status {
            font-size: 24px;
            color: #ff0000;
            margin-bottom: 20px;
        }
        #waveform {
            width: 80%;
            height: 200px;
            background-color: #ffffff;
            border: 1px solid #ccc;
            margin: 0 auto;
        }
    </style>
</head>
<body>
    <div id="status">Initializing...</div>
    <canvas id="waveform"></canvas>

    <script>
        // Configuration
        const SERVER_GET_URL_ENDPOINT = 'http://localhost:3000/get_presigned_url'; // Replace with your server endpoint
        const CHUNK_DURATION_MS = 5000; // Duration of each audio chunk in milliseconds

        // UI Elements
        const statusEl = document.getElementById('status');
        const canvas = document.getElementById('waveform');
        const canvasCtx = canvas.getContext('2d');

        // Audio and Recording Variables
        let mediaRecorder;
        let audioStream;
        let audioContext;
        let analyser;
        let dataArray;
        let animationId;

        // Function to initialize MediaRecorder with preferred MIME type
        function initializeMediaRecorder(stream) {
            let options = { mimeType: 'audio/webm;codecs=opus' };

            if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                if (MediaRecorder.isTypeSupported('audio/ogg;codecs=opus')) {
                    options.mimeType = 'audio/ogg;codecs=opus';
                } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                    options.mimeType = 'audio/webm';
                } else if (MediaRecorder.isTypeSupported('audio/ogg')) {
                    options.mimeType = 'audio/ogg';
                } else {
                    options = {}; // Let the browser choose the default
                }
            }

            try {
                return new MediaRecorder(stream, options);
            } catch (e) {
                console.error('Exception while creating MediaRecorder:', e);
                throw e;
            }
        }

        // Initialize the application
        async function init() {
            try {
                // Request microphone access
                audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                statusEl.textContent = 'Recording now!';
                statusEl.style.color = '#28a745';

                // Setup Audio Context for waveform
                setupAudioContext(audioStream);

                // Start Visualizing the waveform
                visualize();

                // Setup MediaRecorder for recording audio with MIME type selection
                setupMediaRecorder(audioStream);

            } catch (err) {
                console.error('Error accessing microphone:', err);
                statusEl.textContent = 'Microphone access denied.';
                statusEl.style.color = '#dc3545';
            }
        }

        // Setup Audio Context and Analyser for waveform
        function setupAudioContext(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            const bufferLength = analyser.fftSize;
            dataArray = new Uint8Array(bufferLength);
            source.connect(analyser);

            // Resize canvas to fit the window
            resizeCanvas();
            window.addEventListener('resize', resizeCanvas);
        }

        // Resize Canvas based on window size
        function resizeCanvas() {
            canvas.width = window.innerWidth * 0.8;
            canvas.height = 200;
        }

        // Visualize the waveform
        function visualize() {
            function draw() {
                animationId = requestAnimationFrame(draw);

                analyser.getByteTimeDomainData(dataArray);

                canvasCtx.fillStyle = '#ffffff';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

                canvasCtx.lineWidth = 2;
                canvasCtx.strokeStyle = '#007bff';

                canvasCtx.beginPath();

                const sliceWidth = canvas.width * 1.0 / dataArray.length;
                let x = 0;

                for (let i = 0; i < dataArray.length; i++) {
                    const v = dataArray[i] / 128.0;
                    const y = v * canvas.height / 2;

                    if (i === 0) {
                        canvasCtx.moveTo(x, y);
                    } else {
                        canvasCtx.lineTo(x, y);
                    }

                    x += sliceWidth;
                }

                canvasCtx.lineTo(canvas.width, canvas.height / 2);
                canvasCtx.stroke();
            }

            draw();
        }

        // Setup MediaRecorder and handle data chunks
        function setupMediaRecorder(stream) {
            try {
                mediaRecorder = initializeMediaRecorder(stream);
            } catch (e) {
                statusEl.textContent = 'MediaRecorder not supported.';
                statusEl.style.color = '#dc3545';
                return;
            }

            mediaRecorder.ondataavailable = async (event) => {
                if (event.data && event.data.size > 0) {
                    try {
                        const blob = event.data;
                        await uploadChunk(blob);
                    } catch (err) {
                        console.error('Error uploading chunk:', err);
                        // Optionally update UI to inform the user
                    }
                }
            };

            mediaRecorder.onstart = () => {
                console.log('MediaRecorder started');
            };

            mediaRecorder.onstop = () => {
                console.log('MediaRecorder stopped');
            };

            mediaRecorder.onerror = (event) => {
                console.error('MediaRecorder error:', event.error);
                statusEl.textContent = 'Recording error.';
                statusEl.style.color = '#dc3545';
            };

            // Start recording with specified chunk duration
            try {
                mediaRecorder.start(CHUNK_DURATION_MS);
                console.log('MediaRecorder started with chunk duration:', CHUNK_DURATION_MS, 'ms');
            } catch (e) {
                console.error('Failed to start MediaRecorder:', e);
                statusEl.textContent = 'Recording failed to start.';
                statusEl.style.color = '#dc3545';
            }
        }

        // Request a presigned URL from the server and upload the audio chunk
        async function uploadChunk(blob) {
            // Step 1: Get presigned URL from the server
            const response = await fetch(SERVER_GET_URL_ENDPOINT, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    // Include any necessary metadata, e.g., file name, content type
                    fileName: `audio_${Date.now()}.webm`,
                    fileType: blob.type
                })
            });

            if (!response.ok) {
                throw new Error('Failed to get presigned URL');
            }

            const { uploadURL, key } = await response.json();

            // Step 2: Upload the blob to S3 using the presigned URL
            const uploadResponse = await fetch(uploadURL, {
                method: 'PUT',
                headers: {
                    'Content-Type': blob.type
                },
                body: blob
            });

            if (!uploadResponse.ok) {
                throw new Error('Failed to upload audio chunk to S3');
            }

            console.log(`Successfully uploaded chunk: ${key}`);
        }

        // Start the application as soon as the page loads
        window.addEventListener('load', init);

        // Optional: Handle page unload to stop recording and cleanup
        window.addEventListener('beforeunload', () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            if (audioContext) {
                audioContext.close();
            }
        });
    </script>
</body>
</html>
